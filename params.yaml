CHECKPOINT: distilbert-base-uncased
NUM_LABELS: 33
MAX_LENGTH: 512
BATCH_SIZE: 16
EPOCHS: 3
MODEL_DIR: artifacts/model
MODEL_NAME: distilbert-base-uncased
TEST_SIZE: 0.2
TRAIN_SIZE: 0.8
SEED: 42
RANDOM_STATE: 42
LABEL_COL: 'intent'
TEXT_COL: 'instruction'

TRAINING_ARGUMENTS:
  evaluation_strategy: 'epoch'
  save_strategy: 'epoch'
  learning_rate: 2e-5
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  num_train_epochs: 2
  weight_decay: 0.01
  load_best_model_at_end: True
  metric_for_best_model: "f1"