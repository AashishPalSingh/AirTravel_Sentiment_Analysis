{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65805bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a751303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\assi01\\\\Desktop\\\\projects\\\\AirTravel_Sentiment_Analysis\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecfa4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504e3f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\assi01\\\\Desktop\\\\projects\\\\AirTravel_Sentiment_Analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d841e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=False)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    base_tokenizer_path: Path\n",
    "    model_path: Path\n",
    "    tokenizer_path: Path\n",
    "    train_tokenized_data_path: Path\n",
    "    test_tokenized_data_path: Path\n",
    "    val_tokenized_data_path: Path\n",
    "    params_model_name: str\n",
    "    params_eval_strategy: str\n",
    "    params_save_strategy: str\n",
    "    params_learning_rate: float\n",
    "    params_per_device_train_batch_size: int\n",
    "    params_per_device_eval_batch_size: int\n",
    "    params_num_train_epochs: int\n",
    "    params_weight_decay: float\n",
    "    params_load_best_model_at_end: bool\n",
    "    params_metric_for_best_model: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a849d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airTravelSentimentAnalysis.constants import *\n",
    "from airTravelSentimentAnalysis.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422ca28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        config[\"base_model_path\"] = self.config.prepare_base_model.base_model_path\n",
    "        config[\"base_tokenizer_path\"] = self.config.prepare_base_model.base_tokenizer_path\n",
    "        params_training = self.params.TRAINING_ARGUMENTS\n",
    "        print(f\"Training arguments: {params_training}\")\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            base_tokenizer_path=Path(config.base_tokenizer_path),\n",
    "            model_path=Path(config.model_path),\n",
    "            tokenizer_path=Path(config.tokenizer_path),\n",
    "            train_tokenized_data_path=Path(config.train_tokenized_data_path),\n",
    "            test_tokenized_data_path=Path(config.test_tokenized_data_path),\n",
    "            val_tokenized_data_path=Path(config.val_tokenized_data_path),\n",
    "            params_model_name=self.params.MODEL_NAME,\n",
    "            params_eval_strategy=params_training.eval_strategy,\n",
    "            params_save_strategy=params_training.save_strategy,\n",
    "            params_learning_rate=params_training.learning_rate,\n",
    "            params_per_device_train_batch_size=params_training.per_device_train_batch_size,\n",
    "            params_per_device_eval_batch_size=params_training.per_device_eval_batch_size,\n",
    "            params_num_train_epochs=params_training.num_train_epochs,\n",
    "            params_weight_decay=params_training.weight_decay,\n",
    "            params_load_best_model_at_end=params_training.load_best_model_at_end,\n",
    "            params_metric_for_best_model=params_training.metric_for_best_model,\n",
    "        )\n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eecb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q dagshub mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a655889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 10:42:17,619: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ashish.student2025\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as ashish.student2025\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 10:42:17,623: INFO: helpers: Accessing as ashish.student2025]\n",
      "[2025-05-24 10:42:18,204: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/ashish.student2025/AirTravel_SentimentAnalysis \"HTTP/1.1 200 OK\"]\n",
      "[2025-05-24 10:42:18,712: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ashish.student2025/AirTravel_SentimentAnalysis\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"ashish.student2025/AirTravel_SentimentAnalysis\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 10:42:18,715: INFO: helpers: Initialized MLflow to track repo \"ashish.student2025/AirTravel_SentimentAnalysis\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ashish.student2025/AirTravel_SentimentAnalysis initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository ashish.student2025/AirTravel_SentimentAnalysis initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 10:42:18,716: INFO: helpers: Repository ashish.student2025/AirTravel_SentimentAnalysis initialized!]\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "dad = dagshub.init(\n",
    "    repo_owner=\"ashish.student2025\",\n",
    "    repo_name=\"AirTravel_SentimentAnalysis\",\n",
    "    mlflow=True,\n",
    ")\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/ashish.student2025/AirTravel_SentimentAnalysis.mlflow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb8a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] =\"https://dagshub.com\\\\ashish.student2025\\AirTravel_SentimentAnalysis.mlflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"MLFLOW_TRACKING_URI\").split(os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975350cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade \"transformers>=4.37.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6dd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a746ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assi01\\Desktop\\projects\\AirTravel_Sentiment_Analysis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "from torchinfo import summary\n",
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train_dataset = load_from_disk(\"artifacts/text_processing/train\")\n",
    "# tokenized_train_dataset = tokenized_train_dataset.rename_column(\"intent\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train_dataset=tokenized_train_dataset.select(range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b9c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "        print(\"*******************************************************************compute_metrics called +++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits,axis=-1)  # Predicted class is the index of max logit\n",
    "        precision = precision_score(labels, predictions, average=\"weighted\")\n",
    "        recall = recall_score(labels, predictions, average=\"weighted\")\n",
    "        eval_f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e2b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "from torchinfo import summary\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"artifacts/model_training/model.h5\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,  # Learning rate was 2e-5\n",
    "    per_device_train_batch_size=8,  # Batch size for training\n",
    "    per_device_eval_batch_size=8,  # Batch size for evaluation\n",
    "    num_train_epochs=4,  # Number of training epochs\n",
    "    weight_decay=0.01,  # Weight decay for regularization\n",
    "    load_best_model_at_end=True,  # Load best model after training\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"artifacts/prepare_base_model/base_model.h5\"\n",
    ")\n",
    "print(\"*******************without peft*******************\")\n",
    "print(summary(model))\n",
    "print(\"*******************Model*******************\")\n",
    "print(model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"artifacts/model_training/tokenizer.h5\")\n",
    "tokenized_train_dataset = load_from_disk(\"artifacts/text_processing/train\")\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"intent\", \"labels\")\n",
    "tokenized_test_dataset = load_from_disk(\"artifacts/text_processing/test\")\n",
    "tokenized_val_dataset = load_from_disk(\"artifacts/text_processing/val\")\n",
    "tokenized_val_dataset = tokenized_val_dataset.rename_column(\"intent\", \"labels\")\n",
    "tokenized_train_dataset = tokenized_train_dataset.select(range(20))\n",
    "tokenized_test_dataset = tokenized_test_dataset.select(range(20))\n",
    "tokenized_val_dataset = tokenized_val_dataset.select(range(20))\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbccaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def compute_metrics(self,eval_pred):\n",
    "        print(\"*******************************************************************compute_metrics called +++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits,axis=-1)  # Predicted class is the index of max logit\n",
    "        precision = precision_score(labels, predictions, average=\"weighted\")\n",
    "        recall = recall_score(labels, predictions, average=\"weighted\")\n",
    "        eval_f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "\n",
    "    def train(self):\n",
    "        print(self.config)\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=self.config.model_path,\n",
    "            eval_strategy=self.config.params_eval_strategy,\n",
    "            save_strategy=self.config.params_save_strategy,\n",
    "            learning_rate=float(self.config.params_learning_rate),\n",
    "            per_device_train_batch_size=self.config.params_per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=self.config.params_per_device_eval_batch_size,\n",
    "            num_train_epochs=self.config.params_num_train_epochs,\n",
    "            weight_decay=self.config.params_weight_decay,\n",
    "            logging_strategy=\"epoch\",\n",
    "            load_best_model_at_end=self.config.params_load_best_model_at_end,\n",
    "            metric_for_best_model=self.config.params_metric_for_best_model,\n",
    "        )\n",
    "\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.SEQ_CLS,\n",
    "            r=1,\n",
    "            lora_alpha=1,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_lin\", \"v_lin\"]\n",
    "        )\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(self.config.base_model_path)\n",
    "        print(\"*******************without peft*******************\")\n",
    "        print(summary(model))\n",
    "        print(\"*******************Model*******************\")\n",
    "        print(model)\n",
    "        print(\"*******************with peft*******************\")        \n",
    "        peft_model = get_peft_model(model, lora_config)\n",
    "        print(summary(peft_model))\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.base_tokenizer_path)\n",
    "        tokenized_train_dataset = load_from_disk(self.config.train_tokenized_data_path)\n",
    "        tokenized_train_dataset = tokenized_train_dataset.rename_column(\"intent\", \"labels\")\n",
    "        tokenized_test_dataset = load_from_disk(self.config.test_tokenized_data_path) \n",
    "        tokenized_test_dataset = tokenized_test_dataset.rename_column(\n",
    "            \"intent\", \"labels\"\n",
    "        )\n",
    "        tokenized_val_dataset = load_from_disk(self.config.val_tokenized_data_path)\n",
    "        tokenized_val_dataset = tokenized_val_dataset.rename_column(\"intent\", \"labels\")\n",
    "        tokenized_train_dataset = tokenized_train_dataset.select(range(20))\n",
    "        tokenized_test_dataset = tokenized_test_dataset.select(range(20))\n",
    "        tokenized_val_dataset = tokenized_val_dataset.select(range(20))\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train_dataset,\n",
    "            eval_dataset=tokenized_test_dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "        trainer.train()\n",
    "        # mlflow.set_experiment(\"Air Travel Sentiment Analysis\")\n",
    "        # with mlflow.start_run() as run:\n",
    "        #     trainer.train()\n",
    "        #     trainer.evaluate()\n",
    "        #     mlflow.log_metrics(metrics)\n",
    "        # trainer.save_model(self.config.model_path)\n",
    "        # tokenizer.save_pretrained(self.config.tokenizer_path)\n",
    "        # tuned_pipeline = pipeline(\n",
    "        #     task=\"text-classification\",\n",
    "        #     model=trainer.model,\n",
    "        #     batch_size=8,\n",
    "        #     tokenizer=tokenizer,\n",
    "        #     device=\"cpu\",\n",
    "        # )\n",
    "        # model_config = {\"batch_size\": 8}\n",
    "        # signature = mlflow.models.infer_signature(\n",
    "        #     [\"This is a test!\", \"And this is also a test.\"],\n",
    "        #     mlflow.transformers.generate_signature_output(\n",
    "        #         tuned_pipeline, [\"This is a test response!\", \"So is this.\"]\n",
    "        #     ),\n",
    "        #     params=model_config,\n",
    "        # )\n",
    "        # # Log the pipeline to the existing training run\n",
    "        # with mlflow.start_run(run_id=run.info.run_id):\n",
    "        #     model_info = mlflow.transformers.log_model(\n",
    "        #         transformers_model=tuned_pipeline,\n",
    "        #         artifact_path=\"fine_tuned\",\n",
    "        #         signature=signature,\n",
    "        #         input_example=[\"Pass in a string\", \"And have it mark as spam or not.\"],\n",
    "        #         model_config=model_config,\n",
    "        #     )\n",
    "        # print(\"Model saved in run %s\" % model_info.model_uri)\n",
    "        # Load our saved model in the native transformers format\n",
    "        # loaded = mlflow.transformers.load_model(model_uri=model_info.model_uri)\n",
    "\n",
    "        # decoded_texts = ()\n",
    "        # for i in range(len(tokenized_val_dataset)):\n",
    "        #     decoded_text = tokenizer.decode(\n",
    "        #         tokenized_val_dataset[i][\"input_ids\"],\n",
    "        #         skip_special_tokens=True,\n",
    "        #         clean_up_tokenization_spaces=True,\n",
    "        #     )\n",
    "        #     b = list(decoded_texts)\n",
    "        #     b.append(decoded_text)\n",
    "        #     decoded_texts = tuple(b)\n",
    "        # validate the performance of our fine-tuning\n",
    "        # loaded(tokenized_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"artifacts/model_training/model.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fafa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"artifacts/model_training/tokenizer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_pipeline = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    batch_size=8,\n",
    "    tokenizer=tokenizer,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = mlflow.transformers.load_model(\n",
    "    model_uri=\"runs:/d6cd4da81c884535a043ab0947b394da/fine_tuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c19c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_text = (\n",
    "    \"I'd like information about flight ticket prices from Chicago to Madrid\"\n",
    ")\n",
    "loaded(validation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0c233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abf76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"MLFLOW_TRACKING_URI\").split(os.sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ffe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers==4.40.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d05f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    print(\"Model training config: \", model_training_config)\n",
    "    model_training = ModelTraining(config=model_training_config)\n",
    "    model_training.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Transformers location:\", transformers.__file__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
