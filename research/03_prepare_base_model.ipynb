{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba78a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\assi01\\Desktop\\projects\\AirTravel_Sentiment_Analysis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989e6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69de6b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\assi01\\\\Desktop\\\\projects\\\\AirTravel_Sentiment_Analysis\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514e31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36c5b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\assi01\\\\Desktop\\\\projects\\\\AirTravel_Sentiment_Analysis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6957e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=False)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    base_tokenizer_path: Path\n",
    "    updated_base_tokenizer_path: Path\n",
    "    params_checkpoint: str\n",
    "    params_num_labels: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37dea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airTravelSentimentAnalysis.constants import *\n",
    "from airTravelSentimentAnalysis.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcda9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            base_tokenizer_path=Path(config.base_tokenizer_path),\n",
    "            updated_base_tokenizer_path=Path(config.updated_base_tokenizer_path),\n",
    "            params_checkpoint=self.params.CHECKPOINT,\n",
    "            params_num_labels=self.params.NUM_LABELS\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43dba949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ca8b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.config.params_checkpoint, num_labels=self.config.params_num_labels)\n",
    "        self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "        return self.model\n",
    "\n",
    "    def get_base_model_tokenizer(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.config.params_checkpoint)\n",
    "\n",
    "        self.save_model(path=self.config.base_tokenizer_path, model=self.tokenizer)\n",
    "    \n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: AutoModelForSequenceClassification):\n",
    "        model.save_pretrained(path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_tokenizer(path: Path, tokenizer: AutoTokenizer):\n",
    "        tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fead64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-22 22:56:16,906: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-22 22:56:16,908: INFO: common: yaml file content: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://drive.google.com/file/d/1taIeW6BZHqucmJbccEo92qfzZt5X_RTQ/view?usp=sharing', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'prepare_base_model': {'root_dir': 'artifacts/prepare_base_model', 'base_model_path': 'artifacts/prepare_base_model/base_model.h5', 'updated_base_model_path': 'artifacts/prepare_base_model/base_model_updated.h5', 'base_tokenizer_path': 'artifacts/prepare_base_tokenizer/base_model.h5', 'updated_base_tokenizer_path': 'artifacts/prepare_base_tokenizer/base_model_updated.h5'}, 'data_preprocessing': {'root_dir': 'artifacts/data_preprocessing', 'raw_data_file': 'artifacts/data_ingestion/bitext-travel-llm-chatbot-training-dataset.csv', 'train_data_path': 'artifacts/data_preprocessing/train.csv', 'test_data_path': 'artifacts/data_preprocessing/test.csv', 'val_data_path': 'artifacts/data_preprocessing/val.csv'}, 'text_processing': {'root_dir': 'artifacts/text_processing', 'train_tokenized_data_path': 'artifacts/text_processing/train_tokenized.csv', 'test_tokenized_data_path': 'artifacts/text_processing/test_tokenized.csv', 'val_tokenized_data_path': 'artifacts/text_processing/val_tokenized.csv'}} ]\n",
      "[2025-05-22 22:56:16,909: INFO: common: datapreprocessing file content: {'root_dir': 'artifacts/data_preprocessing', 'raw_data_file': 'artifacts/data_ingestion/bitext-travel-llm-chatbot-training-dataset.csv', 'train_data_path': 'artifacts/data_preprocessing/train.csv', 'test_data_path': 'artifacts/data_preprocessing/test.csv', 'val_data_path': 'artifacts/data_preprocessing/val.csv'} ]\n",
      "[2025-05-22 22:56:16,911: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-22 22:56:16,912: INFO: common: yaml file content: {'CHECKPOINT': 'distilbert-base-uncased', 'NUM_LABELS': 33, 'MAX_LENGTH': 512, 'BATCH_SIZE': 16, 'EPOCHS': 3, 'MODEL_DIR': 'artifacts/model', 'MODEL_NAME': 'distilbert-base-uncased', 'TEST_SIZE': 0.2, 'TRAIN_SIZE': 0.8, 'SEED': 42, 'RANDOM_STATE': 42, 'LABEL_COL': 'intent', 'TEXT_COL': 'instruction'} ]\n",
      "[2025-05-22 22:56:16,912: INFO: common: datapreprocessing file content: None ]\n",
      "[2025-05-22 22:56:16,915: INFO: common: created directory at: artifacts]\n",
      "[2025-05-22 22:56:16,918: INFO: common: created directory at: artifacts/prepare_base_model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "DistilBertForSequenceClassification                     --\n",
      "├─DistilBertModel: 1-1                                  --\n",
      "│    └─Embeddings: 2-1                                  --\n",
      "│    │    └─Embedding: 3-1                              23,440,896\n",
      "│    │    └─Embedding: 3-2                              393,216\n",
      "│    │    └─LayerNorm: 3-3                              1,536\n",
      "│    │    └─Dropout: 3-4                                --\n",
      "│    └─Transformer: 2-2                                 --\n",
      "│    │    └─ModuleList: 3-5                             42,527,232\n",
      "├─Linear: 1-2                                           590,592\n",
      "├─Linear: 1-3                                           25,377\n",
      "├─Dropout: 1-4                                          --\n",
      "================================================================================\n",
      "Total params: 66,978,849\n",
      "Trainable params: 66,978,849\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    base_model = prepare_base_model.get_base_model()\n",
    "    prepare_base_model.get_base_model_tokenizer()\n",
    "    print(summary(base_model))\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3aba3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
